{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting cloud cover using neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "np.random.seed(12)\n",
    "\n",
    "import warnings\n",
    "#Comment this to turn on warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from model_comparison import model_comparison\n",
    "from resample import resample\n",
    "import algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import netCDF4 as n\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils import train_test_split\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "\n",
    "from deepNN import NeuralNetRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from utils import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading test\n",
    "path = \"./files/\"\n",
    "filenames = [\"specific_humidity_Europa_sp.nc\", \"relative_humidity_Europa_sp.nc\", \"pressure_Europa_sp.nc\",  \n",
    "             \"temperature_Europa_sp.nc\", \"total_cloud_cover_Europa_sp.nc\"]\n",
    "\n",
    "\n",
    "cloud = n.Dataset(path + filenames[-1], \"r\")\n",
    "relative = n.Dataset(path + filenames[1], \"r\")\n",
    "specific = n.Dataset(path + filenames[0], \"r\")\n",
    "pressure = n.Dataset(path + filenames[2], \"r\")\n",
    "temperature = n.Dataset(path + filenames[3], \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cloud.variables)\n",
    "tcc = cloud.variables[\"tcc\"][:][:][:].data\n",
    "\n",
    "# Retriving ground values, these are available at six different pressure levels. \n",
    "rel = relative.variables[\"r\"][:][:][:][:].data\n",
    "#level = relative.variables[\"level\"][:][0].data\n",
    "spe = specific.variables[\"q\"][:][:][:][:].data\n",
    "\n",
    "surf_pre = pressure.variables[\"sp\"][:][:][:].data\n",
    "temp = temperature.variables[\"t2m\"][:][:][:].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_inv(x): # sigmoid?\n",
    "    return np.exp(x)/(1+np.exp(x))\n",
    "\n",
    "def logit(x):\n",
    "    return np.log10((x + 1e-12)/(1+1e-12 - x))\n",
    "\n",
    "\n",
    "\n",
    "#from scipy.special import logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one certain timestep \n",
    "\n",
    "n_days = 0.25\n",
    "\n",
    "TCC = []\n",
    "REL = []\n",
    "SPE = []\n",
    "PRE = []\n",
    "TEMP = []\n",
    "\n",
    "\n",
    "for t in range(int(n_days*4)):\n",
    "    TCC.append(tcc[t].flatten())\n",
    "    REL.append(rel[t][0].flatten())\n",
    "    SPE.append(spe[t][0].flatten())\n",
    "    PRE.append(surf_pre[t].flatten())\n",
    "    TEMP.append(temp[t].flatten())\n",
    "   \n",
    "y = logit(np.array(TCC).flatten()) #logit(tcc[0].flatten()).reshape((4697, 1))\n",
    "X = np.array([np.array(REL).flatten(),np.array(SPE).flatten(), np.array(PRE).flatten(),np.array(TEMP).flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.99866855977416e-13, 1.0000000000009999)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(TCC).min(), np.array(TCC).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-11.698998917155576, 15.65355977452789)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min(), y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 4697), (4697,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X), np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape((len(y),1))\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4697, 4), (4697, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X), np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, split_size = 0.2)\n",
    "import sklearn.model_selection as s\n",
    "X_train, X_test, y_train, y_test = s.train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3757, 4), (3757, 1), (940, 4), (940, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train), np.shape(y_train), np.shape(X_test), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.65355977452789, -11.698998917155576)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.max(), y_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-12.000000000000433, 11.999961392684167)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit(0), logit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for epochs :10 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 10 traininperformance ois [43.85612127363853]validation performance is [41.75631026994696]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 30 traininperformance ois [43.857668176740056]validation performance is [41.76242492626194]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 50 traininperformance ois [43.93218473784389]validation performance is [41.88758605858721]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 100 traininperformance ois [43.8654870744613]validation performance is [41.78189098434261]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 500 traininperformance ois [43.855521489320644]validation performance is [41.75227110614712]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 10 traininperformance ois [43.87602283154052]validation performance is [41.738528976734536]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 30 traininperformance ois [44.409699587367506]validation performance is [42.46829367577688]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 50 traininperformance ois [44.21091369166053]validation performance is [41.97349110809979]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 100 traininperformance ois [43.90913613874596]validation performance is [41.854539103195954]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 500 traininperformance ois [43.871734501427355]validation performance is [41.73772803375868]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 10 traininperformance ois [50.80887552694129]validation performance is [48.120910100848015]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 30 traininperformance ois [44.036333972641245]validation performance is [42.024467349660846]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 50 traininperformance ois [54.5235585273272]validation performance is [51.69666296768566]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 100 traininperformance ois [54.86057250455684]validation performance is [53.48720805016762]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 500 traininperformance ois [69.13437756060519]validation performance is [65.91855509083085]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 10 traininperformance ois [43.85564683992959]validation performance is [41.753403410005866]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 30 traininperformance ois [43.87157257571897]validation performance is [41.73770627341968]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 50 traininperformance ois [43.85684494833588]validation performance is [41.742643090091875]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 100 traininperformance ois [43.86010527462813]validation performance is [41.76948471380149]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 500 traininperformance ois [43.85555724942622]validation performance is [41.74692223887133]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 10 traininperformance ois [43.9589601230152]validation performance is [41.924231300890376]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 30 traininperformance ois [44.71741769222103]validation performance is [42.406652832104065]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 50 traininperformance ois [45.722015706360786]validation performance is [43.9178742444492]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 100 traininperformance ois [44.95612055265122]validation performance is [43.081972437528115]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 500 traininperformance ois [44.33253108149168]validation performance is [42.37925478373591]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 10 traininperformance ois [7.386363030368658e+298]validation performance is [7.386363030368659e+298]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 30 traininperformance ois [inf]validation performance is [1.0849490830917063e+305]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 50 traininperformance ois [4.6909583044359225e+304]validation performance is [4.6909583044359225e+304]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 100 traininperformance ois [inf]validation performance is [inf]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 500 traininperformance ois [2.8017720106588173e+304]validation performance is [2.801772010658817e+304]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 10 traininperformance ois [43.86098004401477]validation performance is [41.77170597832289]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 30 traininperformance ois [43.85566716281972]validation performance is [41.74621156037536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for epochs :10 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 50 traininperformance ois [43.85937511440868]validation performance is [41.73965715473431]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 100 traininperformance ois [43.85787239816172]validation performance is [41.74109177202967]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 500 traininperformance ois [43.86050111989769]validation performance is [41.7705041021339]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 10 traininperformance ois [44.11536784418765]validation performance is [42.12215825606282]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 30 traininperformance ois [45.0836958022045]validation performance is [42.7332269693122]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 50 traininperformance ois [44.02061391438877]validation performance is [41.825091079828944]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 100 traininperformance ois [44.097474384484045]validation performance is [42.10032177551912]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 500 traininperformance ois [45.204124901339824]validation performance is [42.84194129478829]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :10 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 10 traininperformance ois [43.856408598465016]validation performance is [41.75767362485798]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 30 traininperformance ois [43.86079921856963]validation performance is [41.77125597350203]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 50 traininperformance ois [43.8825416152849]validation performance is [41.74038131387337]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 100 traininperformance ois [43.86329258418867]validation performance is [41.777138141203324]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 500 traininperformance ois [43.86102061861716]validation performance is [41.73867320581755]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 10 traininperformance ois [44.34749175603174]validation performance is [42.396587882215044]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 30 traininperformance ois [45.191155630953496]validation performance is [42.830207771263936]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 50 traininperformance ois [44.95798588035499]validation performance is [43.08403394770867]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 100 traininperformance ois [43.85732276037287]validation performance is [41.741836051340044]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 500 traininperformance ois [44.00519411496808]validation performance is [41.81396149395348]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 10 traininperformance ois [51.427303453445305]validation performance is [48.71400028212879]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 30 traininperformance ois [48.623832236384494]validation performance is [46.03593967929449]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 50 traininperformance ois [48.60389911578518]validation performance is [46.01701527965548]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 100 traininperformance ois [49.33130118703119]validation performance is [46.70888082942997]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 500 traininperformance ois [44.47293130803207]validation performance is [42.54064763723434]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 10 traininperformance ois [43.952946842545956]validation performance is [41.77820746887742]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 30 traininperformance ois [43.869748336415284]validation performance is [41.79042260896133]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 50 traininperformance ois [43.857196656987334]validation performance is [41.74203194023439]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 100 traininperformance ois [43.86714982160285]validation performance is [41.737427143465524]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 500 traininperformance ois [43.86168963239085]validation performance is [41.73838562007758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for epochs :50 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 10 traininperformance ois [44.30184344322251]validation performance is [42.04854377421456]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 30 traininperformance ois [43.863916215576175]validation performance is [41.73774926362416]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 50 traininperformance ois [44.95115166998989]validation performance is [43.07648014893486]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 100 traininperformance ois [44.08830545083477]validation performance is [42.08907584005261]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 500 traininperformance ois [44.529228763850476]validation performance is [42.60468096813619]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 10 traininperformance ois [43.856362066637416]validation performance is [41.75746425633082]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 30 traininperformance ois [43.85816526703187]validation performance is [41.764015026077864]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 50 traininperformance ois [43.85569127072276]validation performance is [41.74607911393791]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 100 traininperformance ois [43.858563543248195]validation performance is [41.765219917867974]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 500 traininperformance ois [43.855648915149075]validation performance is [41.7534197541912]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 10 traininperformance ois [44.824785605471845]validation performance is [42.936379930918584]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 30 traininperformance ois [44.91923259250055]validation performance is [42.585733369950105]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 50 traininperformance ois [44.872668626896]validation performance is [42.54420873564166]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 100 traininperformance ois [43.95288804615929]validation performance is [41.91604495706644]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 500 traininperformance ois [43.99947159734659]validation performance is [41.80988699870846]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :50 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 10 traininperformance ois [43.85584375058081]validation performance is [41.7547651900947]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 30 traininperformance ois [43.91166857378242]validation performance is [41.85826351250403]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 50 traininperformance ois [43.91156213476564]validation performance is [41.858107521084555]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 100 traininperformance ois [43.85588213223208]validation performance is [41.74520412043427]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.0001noden in middle layer n: 500 traininperformance ois [43.86635793561592]validation performance is [41.783698777185904]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 10 traininperformance ois [44.167415790524316]validation performance is [41.938308966973224]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 30 traininperformance ois [44.757471821351956]validation performance is [42.44199873875993]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 50 traininperformance ois [43.867479086606295]validation performance is [41.73742354328619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for epochs :100 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 100 traininperformance ois [43.868900899092914]validation performance is [41.78878259431079]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.001noden in middle layer n: 500 traininperformance ois [44.00336983772214]validation performance is [41.98251887993221]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 10 traininperformance ois [44.20413082128241]validation performance is [41.96797005119172]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 30 traininperformance ois [46.70020407949172]validation performance is [44.22204322546672]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 50 traininperformance ois [66.55476388636977]validation performance is [65.50086345782267]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 100 traininperformance ois [61.85882335721243]validation performance is [60.689821408003574]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.01noden in middle layer n: 500 traininperformance ois [49.44682895655598]validation performance is [47.863109078056254]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 0.1noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 1 learningrat e : 1.0noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 10 traininperformance ois [43.855844749262445]validation performance is [41.75477136208846]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 30 traininperformance ois [43.86158350689032]validation performance is [41.73842772475837]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 50 traininperformance ois [43.85581988234135]validation performance is [41.745462143908384]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 100 traininperformance ois [43.85586351781745]validation performance is [41.74527903800272]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.0001noden in middle layer n: 500 traininperformance ois [43.85761441571177]validation performance is [41.74142107046234]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 10 traininperformance ois [45.51171565583965]validation performance is [43.69007475173745]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 30 traininperformance ois [44.961669123645265]validation performance is [43.08810408272589]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 50 traininperformance ois [43.857339309739615]validation performance is [41.76130580704099]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 100 traininperformance ois [45.76901954385193]validation performance is [43.96865228787298]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.001noden in middle layer n: 500 traininperformance ois [43.93495187650414]validation performance is [41.89144573027749]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.01noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 0.1noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 10 learningrat e : 1.0noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 10 traininperformance ois [43.87418513744642]validation performance is [41.73813650559167]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 30 traininperformance ois [43.89885134971685]validation performance is [41.747043749240596]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 50 traininperformance ois [43.859452423541065]validation performance is [41.739599922620314]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 100 traininperformance ois [43.85886973888684]validation performance is [41.766112317364275]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.0001noden in middle layer n: 500 traininperformance ois [43.90812558668505]validation performance is [41.75164441450485]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 10 traininperformance ois [45.07136169948458]validation performance is [43.2090372290351]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 30 traininperformance ois [44.02257473667475]validation performance is [42.0070668356953]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 50 traininperformance ois [45.49711324458981]validation performance is [43.674217057791054]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 100 traininperformance ois [44.74528053263949]validation performance is [42.431229225259436]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.001noden in middle layer n: 500 traininperformance ois [44.087187058776195]validation performance is [42.087701326070174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for epochs :100 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.01noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 0.1noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 10 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 30 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 50 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 100 traininperformance ois [nan]validation performance is [nan]\n",
      " for epochs :100 for bactsize : 50 learningrat e : 1.0noden in middle layer n: 500 traininperformance ois [nan]validation performance is [nan]\n"
     ]
    }
   ],
   "source": [
    "n_nodes = [10,30,50,100, 500]\n",
    "eta = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "lmd = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "epochs = [10,50,100]\n",
    "batch_s = [1,10,50]\n",
    "\n",
    "\n",
    "for e in epochs:\n",
    "    for b in batch_s:\n",
    "        for et in eta:\n",
    "            for n in n_nodes:\n",
    "                model = NeuralNetRegressor(n_hidden = [30,n,20],  \n",
    "                                           epochs=e, \n",
    "                                           eta=et, \n",
    "                                           shuffle=True, \n",
    "                                           batch_size=b,\n",
    "                                           seed=None, \n",
    "                                           alpha=0.0001, \n",
    "                                           activation='sigmoid')\n",
    "\n",
    "                p = model.fit(X_train, y_train, X_test, y_test)\n",
    "                l = model.predict(X_test)\n",
    "                print( \" for epochs :\" + str(e) + \" for bactsize : \" + str(b) + \" learningrat e : \" + str(et) + \"noden in middle layer n: \" + str(n) + \" traininperformance ois \" + str(p.eval_['train_preform']) + \"validation performance is \"+ str(p.eval_['valid_preform']))\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43.85544507500887]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.eval_['train_preform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41.74802762583487]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.eval_['valid_preform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit MLP Regressor using several layers of depth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLPRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-cac5435e74aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         mlp = MLPRegressor(hidden_layer_sizes=(30,10, 20), \n\u001b[0m\u001b[1;32m     14\u001b[0m                            \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# this is the sigmoid activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                            \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MLPRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "n_nodes = [10,30,50,100, 500]\n",
    "eta = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "lmd = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "epochs = [10,50,100]\n",
    "batch_s = [1,10,50]\n",
    "\n",
    "#for e in epochs:\n",
    "for b in batch_s:\n",
    "    for et in eta:\n",
    "            #for n in n_nodes:\n",
    "\n",
    "\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=(30,10, 20), \n",
    "                           activation = 'relu', # this is the sigmoid activation function\n",
    "                           solver = \"adam\", \n",
    "                           alpha = 0.0001, \n",
    "                           batch_size =b, \n",
    "                           learning_rate_init=e)\n",
    "\n",
    "        mlp.fit(X_train, y_train)\n",
    "        y_pred = mlp.predict(X_test)\n",
    "        #logistic activation uses the sigmoid function \n",
    "        mse = mean_squared_error(y_pred, y_test)\n",
    "        print(\" for nr nodes:   \" + str(n) + \" eta : \" + str(e) + \" penalty l  \" + str(l) + \"   mse is \" + str(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
