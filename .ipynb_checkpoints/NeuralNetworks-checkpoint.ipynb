{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting cloud cover using neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "np.random.seed(12)\n",
    "\n",
    "import warnings\n",
    "#Comment this to turn on warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from model_comparison import model_comparison\n",
    "from resample import resample\n",
    "import algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import netCDF4 as n\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils import train_test_split\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from deepNN import NeuralNetRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from utils import mean_squared_error, A_R2, NRMSE, transforming_predictorspace, standardicing_responce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading test\n",
    "path = \"./files/\"\n",
    "filenames = [\"specific_humidity_Europa_sp.nc\", \"relative_humidity_Europa_sp.nc\", \"pressure_Europa_sp.nc\",  \n",
    "             \"temperature_Europa_sp.nc\", \"total_cloud_cover_Europa_sp.nc\"]\n",
    "\n",
    "\n",
    "cloud = n.Dataset(path + filenames[-1], \"r\")\n",
    "relative = n.Dataset(path + filenames[1], \"r\")\n",
    "specific = n.Dataset(path + filenames[0], \"r\")\n",
    "pressure = n.Dataset(path + filenames[2], \"r\")\n",
    "temperature = n.Dataset(path + filenames[3], \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cloud.variables)\n",
    "tcc = cloud.variables[\"tcc\"][:][:][:].data\n",
    "\n",
    "# Retriving ground values, these are available at six different pressure levels. \n",
    "rel = relative.variables[\"r\"][:][:][:][:].data\n",
    "#level = relative.variables[\"level\"][:][0].data\n",
    "spe = specific.variables[\"q\"][:][:][:][:].data\n",
    "\n",
    "surf_pre = pressure.variables[\"sp\"][:][:][:].data\n",
    "temp = temperature.variables[\"t2m\"][:][:][:].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_inv(x): # sigmoid?\n",
    "    return np.exp(x)/(1+np.exp(x))\n",
    "\n",
    "def logit(x):\n",
    "    return np.log((x + 1e-12)/(1+1e-12 - x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one certain timestep \n",
    "\n",
    "n_days = 7\n",
    "\n",
    "TCC = []\n",
    "REL = []\n",
    "SPE = []\n",
    "PRE = []\n",
    "TEMP = []\n",
    "\n",
    "\n",
    "for t in range(int(n_days*4)):\n",
    "    TCC.append(tcc[t][:][:].flatten())\n",
    "    REL.append(rel[t][0][:][:].flatten())\n",
    "    SPE.append(spe[t][0][:][:].flatten())\n",
    "    PRE.append(surf_pre[t][:][:].flatten())\n",
    "    TEMP.append(temp[t][:][:].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "y =(np.array(TCC).flatten())\n",
    "temp = y[y<1]\n",
    "y[y>1] = temp.max()\n",
    "print(y.min()>0)\n",
    "\n",
    "X = np.array([np.array(REL).flatten(), np.array(SPE).flatten(), np.array(PRE).flatten(), np.array(TEMP).flatten()])\n",
    "y = logit(np.array(TCC).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.99866855977416e-13, 1.0000000000009999)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(TCC).min(), np.array(TCC).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-26.93794050959591, 36.04365338911916)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min(), y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((131516,), (131516,), (131516,), (131516,), (131516,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X[0]),np.shape(X[1]),np.shape(X[2]),np.shape(X[3]), np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape((len(y),1))\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((131516, 4), (131516, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X), np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.preprocessing import StandardScaler\\nscaler = StandardScaler()\\nfit = scaler.fit(X_train)\\n\\nX_train = scaler.transform(X_train)\\nX_test = scaler.transform(X_test)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, split_size = 0.2)\n",
    "import sklearn.model_selection as s\n",
    "X_train, X_test, y_train, y_test = s.train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "\"\"\"from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "fit = scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105212, 4), (26304, 4), (105212, 1), (26304, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train), np.shape(X_test), np.shape(y_train),  np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36.04365338911916, -26.93794050959591)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.max(), y_train.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Layer MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0 cost train: [[2430325.90190533]]\n",
      " Epoch 0 cost test: [[653346.78765196]]\n",
      "   \n",
      " Epoch 1 cost train: [[7955.15890789]]\n",
      " Epoch 1 cost test: [[13594.59619928]]\n",
      "   \n",
      " Epoch 2 cost train: [[7964.6433994]]\n",
      " Epoch 2 cost test: [[13610.02506035]]\n",
      "   \n",
      " Epoch 3 cost train: [[7967.17484844]]\n",
      " Epoch 3 cost test: [[13641.69820522]]\n",
      "   \n",
      " Epoch 4 cost train: [[7979.99189609]]\n",
      " Epoch 4 cost test: [[13527.20570818]]\n",
      "   \n",
      " Epoch 5 cost train: [[7992.60376176]]\n",
      " Epoch 5 cost test: [[13501.14897191]]\n",
      "   \n",
      " Epoch 6 cost train: [[7964.68721418]]\n",
      " Epoch 6 cost test: [[13601.60454941]]\n",
      "   \n",
      " Epoch 7 cost train: [[7973.1459335]]\n",
      " Epoch 7 cost test: [[13671.3899604]]\n",
      "   \n",
      " Epoch 8 cost train: [[7974.85963251]]\n",
      " Epoch 8 cost test: [[13541.29890546]]\n",
      "   \n",
      " Epoch 9 cost train: [[7996.34005599]]\n",
      " Epoch 9 cost test: [[13735.04637669]]\n",
      "   \n",
      " Epoch 10 cost train: [[7980.48089161]]\n",
      " Epoch 10 cost test: [[13695.89413061]]\n",
      "   \n",
      " Epoch 11 cost train: [[7964.92237874]]\n",
      " Epoch 11 cost test: [[13618.72915997]]\n",
      "   \n",
      " Epoch 12 cost train: [[7971.21668766]]\n",
      " Epoch 12 cost test: [[13553.86201965]]\n",
      "   \n",
      " Epoch 13 cost train: [[7965.17122359]]\n",
      " Epoch 13 cost test: [[13591.33225287]]\n",
      "   \n",
      " Epoch 14 cost train: [[7965.43512432]]\n",
      " Epoch 14 cost test: [[13587.9686771]]\n",
      "   \n",
      " Epoch 15 cost train: [[7964.62378104]]\n",
      " Epoch 15 cost test: [[13607.5117244]]\n",
      "   \n",
      " Epoch 16 cost train: [[7969.75930639]]\n",
      " Epoch 16 cost test: [[13656.61269152]]\n",
      "   \n",
      " Epoch 17 cost train: [[7965.1259741]]\n",
      " Epoch 17 cost test: [[13591.9868832]]\n",
      "   \n",
      " Epoch 18 cost train: [[7965.15173437]]\n",
      " Epoch 18 cost test: [[13622.62659694]]\n",
      "   \n",
      " Epoch 19 cost train: [[7978.05846076]]\n",
      " Epoch 19 cost test: [[13532.15909799]]\n",
      "   \n",
      " Epoch 20 cost train: [[7973.26911854]]\n",
      " Epoch 20 cost test: [[13671.86917738]]\n",
      "   \n",
      " Epoch 21 cost train: [[7966.45132818]]\n",
      " Epoch 21 cost test: [[13578.6023283]]\n",
      "   \n",
      " Epoch 22 cost train: [[7973.59131972]]\n",
      " Epoch 22 cost test: [[13673.10772855]]\n",
      "   \n",
      " Epoch 23 cost train: [[7965.31228202]]\n",
      " Epoch 23 cost test: [[13624.86602429]]\n",
      "   \n",
      " Epoch 24 cost train: [[8032.25229018]]\n",
      " Epoch 24 cost test: [[13799.3125097]]\n",
      "   \n",
      " Epoch 25 cost train: [[7968.2719701]]\n",
      " Epoch 25 cost test: [[13648.64448007]]\n",
      "   \n",
      " Epoch 26 cost train: [[7964.85830232]]\n",
      " Epoch 26 cost test: [[13596.70199149]]\n",
      "   \n",
      " Epoch 27 cost train: [[7965.0111461]]\n",
      " Epoch 27 cost test: [[13620.36989415]]\n",
      "   \n",
      " Epoch 28 cost train: [[7974.2219727]]\n",
      " Epoch 28 cost test: [[13675.4732776]]\n",
      "   \n",
      " Epoch 29 cost train: [[7965.29294206]]\n",
      " Epoch 29 cost test: [[13624.61094181]]\n",
      "   \n",
      " Epoch 30 cost train: [[7964.63415202]]\n",
      " Epoch 30 cost test: [[13609.22409351]]\n",
      "   \n",
      " Epoch 31 cost train: [[7966.88778807]]\n",
      " Epoch 31 cost test: [[13639.65263931]]\n",
      "   \n",
      " Epoch 32 cost train: [[7966.45598193]]\n",
      " Epoch 32 cost test: [[13636.32263923]]\n",
      "   \n",
      " Epoch 33 cost train: [[7969.3116891]]\n",
      " Epoch 33 cost test: [[13561.97110583]]\n",
      "   \n",
      " Epoch 34 cost train: [[7971.90654856]]\n",
      " Epoch 34 cost test: [[13551.24038899]]\n",
      "   \n",
      " Epoch 35 cost train: [[7979.52551374]]\n",
      " Epoch 35 cost test: [[13528.3677052]]\n",
      "   \n",
      " Epoch 36 cost train: [[7985.14546651]]\n",
      " Epoch 36 cost test: [[13708.74915326]]\n",
      "   \n",
      " Epoch 37 cost train: [[7968.0113855]]\n",
      " Epoch 37 cost test: [[13568.56975498]]\n",
      "   \n",
      " Epoch 38 cost train: [[7971.14338883]]\n",
      " Epoch 38 cost test: [[13554.14899521]]\n",
      "   \n",
      " Epoch 39 cost train: [[7964.62370769]]\n",
      " Epoch 39 cost test: [[13607.47890091]]\n",
      "   \n",
      " Epoch 40 cost train: [[8018.14032364]]\n",
      " Epoch 40 cost test: [[13464.31981254]]\n",
      "   \n",
      " Epoch 41 cost train: [[7970.05376636]]\n",
      " Epoch 41 cost test: [[13658.05275003]]\n",
      "   \n",
      " Epoch 42 cost train: [[7995.78041932]]\n",
      " Epoch 42 cost test: [[13495.71031139]]\n",
      "   \n",
      " Epoch 43 cost train: [[8051.50073978]]\n",
      " Epoch 43 cost test: [[13827.52729821]]\n",
      "   \n",
      " Epoch 44 cost train: [[7968.21025988]]\n",
      " Epoch 44 cost test: [[13567.48359087]]\n",
      "   \n",
      " Epoch 45 cost train: [[7964.68833979]]\n",
      " Epoch 45 cost test: [[13601.55759761]]\n",
      "   \n",
      " Epoch 46 cost train: [[7965.77825728]]\n",
      " Epoch 46 cost test: [[13630.20052823]]\n",
      "   \n",
      " Epoch 47 cost train: [[7987.54549831]]\n",
      " Epoch 47 cost test: [[13510.59118308]]\n",
      "   \n",
      " Epoch 48 cost train: [[7964.77296529]]\n",
      " Epoch 48 cost test: [[13598.76834235]]\n",
      "   \n",
      " Epoch 49 cost train: [[7964.62317576]]\n",
      " Epoch 49 cost test: [[13607.00369656]]\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetRegressor(n_hidden = [10],  \n",
    "                           epochs=50, \n",
    "                           eta=0.001, \n",
    "                           shuffle=True, \n",
    "                           batch_size=10,\n",
    "                           seed=None, \n",
    "                           alpha=0.0001, # dette er for relu ikke det samme som penaltien i scikit learn  \n",
    "                           activation='sigmoid')\n",
    "\n",
    "p = model.fit(X_train, y_train, X_test, y_test)\n",
    "l = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Transformin the predictor space, standardizing the response, calculating the performance metrics\n",
    "# This is done in the neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.411374795837078,\n",
       " 0.4084198658218838,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254,\n",
       " 0.4077891826020254]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.eval_['train_preform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " 2.0000000000000004,\n",
       " nan,\n",
       " 2.0000000000000004,\n",
       " 2.0,\n",
       " nan,\n",
       " 2.0000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 2.0000000000000004,\n",
       " nan,\n",
       " 2.0000000000000004,\n",
       " nan,\n",
       " nan,\n",
       " 2.0000000000000004,\n",
       " 2.0000000000000004,\n",
       " 2.0,\n",
       " nan,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0000000000000004,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0000000000000004,\n",
       " 2.0,\n",
       " nan,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0000000000000004,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " nan,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0000000000000004,\n",
       " 2.0,\n",
       " 2.0,\n",
       " nan,\n",
       " nan,\n",
       " 2.0000000000000004,\n",
       " 2.0000000000000004,\n",
       " 2.0000000000000004,\n",
       " 2.0,\n",
       " 2.0,\n",
       " nan,\n",
       " 2.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.eval_['valid_preform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2430325.90190533]]),\n",
       " array([[7955.15890789]]),\n",
       " array([[7964.6433994]]),\n",
       " array([[7967.17484844]]),\n",
       " array([[7979.99189609]]),\n",
       " array([[7992.60376176]]),\n",
       " array([[7964.68721418]]),\n",
       " array([[7973.1459335]]),\n",
       " array([[7974.85963251]]),\n",
       " array([[7996.34005599]]),\n",
       " array([[7980.48089161]]),\n",
       " array([[7964.92237874]]),\n",
       " array([[7971.21668766]]),\n",
       " array([[7965.17122359]]),\n",
       " array([[7965.43512432]]),\n",
       " array([[7964.62378104]]),\n",
       " array([[7969.75930639]]),\n",
       " array([[7965.1259741]]),\n",
       " array([[7965.15173437]]),\n",
       " array([[7978.05846076]]),\n",
       " array([[7973.26911854]]),\n",
       " array([[7966.45132818]]),\n",
       " array([[7973.59131972]]),\n",
       " array([[7965.31228202]]),\n",
       " array([[8032.25229018]]),\n",
       " array([[7968.2719701]]),\n",
       " array([[7964.85830232]]),\n",
       " array([[7965.0111461]]),\n",
       " array([[7974.2219727]]),\n",
       " array([[7965.29294206]]),\n",
       " array([[7964.63415202]]),\n",
       " array([[7966.88778807]]),\n",
       " array([[7966.45598193]]),\n",
       " array([[7969.3116891]]),\n",
       " array([[7971.90654856]]),\n",
       " array([[7979.52551374]]),\n",
       " array([[7985.14546651]]),\n",
       " array([[7968.0113855]]),\n",
       " array([[7971.14338883]]),\n",
       " array([[7964.62370769]]),\n",
       " array([[8018.14032364]]),\n",
       " array([[7970.05376636]]),\n",
       " array([[7995.78041932]]),\n",
       " array([[8051.50073978]]),\n",
       " array([[7968.21025988]]),\n",
       " array([[7964.68833979]]),\n",
       " array([[7965.77825728]]),\n",
       " array([[7987.54549831]]),\n",
       " array([[7964.77296529]]),\n",
       " array([[7964.62317576]])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.eval_['cost_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = p.eval_['cost_train']\n",
    "te = p.eval_['cost_test']\n",
    "\n",
    "x = np.arange(100)\n",
    "temp = []\n",
    "temp2 = []\n",
    "for i in range(len(x)):\n",
    "    temp.append(tr[i][0][0])\n",
    "    temp2.append(te[i][0][0])\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(x,temp, label = \"cost train\")\n",
    "#plt.plot(x,temp2, label = \"cost test\")\n",
    "plt.legend()\n",
    "plt.savefig(\"results/figures/cost_nn_one_layer.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0 cost train: [[2756566.40713267]]\n",
      " Epoch 0 cost test: [[737132.91230565]]\n",
      "   \n",
      " Epoch 1 cost train: [[7971.20621831]]\n",
      " Epoch 1 cost test: [[13702.98685113]]\n",
      "   \n",
      " Epoch 2 cost train: [[7989.65937181]]\n",
      " Epoch 2 cost test: [[13506.51451743]]\n",
      "   \n",
      " Epoch 3 cost train: [[7997.90101867]]\n",
      " Epoch 3 cost test: [[13492.25529397]]\n",
      "   \n",
      " Epoch 4 cost train: [[8259.91034628]]\n",
      " Epoch 4 cost test: [[13314.26399076]]\n",
      "   \n",
      " Epoch 5 cost train: [[8010.94971453]]\n",
      " Epoch 5 cost test: [[13763.75381045]]\n",
      "   \n",
      " Epoch 6 cost train: [[7977.77045084]]\n",
      " Epoch 6 cost test: [[13532.92966651]]\n",
      "   \n",
      " Epoch 7 cost train: [[7990.15336007]]\n",
      " Epoch 7 cost test: [[13505.59020716]]\n",
      "   \n",
      " Epoch 8 cost train: [[8045.16368164]]\n",
      " Epoch 8 cost test: [[13435.69032767]]\n",
      "   \n",
      " Epoch 9 cost train: [[7988.61195817]]\n",
      " Epoch 9 cost test: [[13717.45874467]]\n",
      "   \n",
      " Epoch 10 cost train: [[7968.6208704]]\n",
      " Epoch 10 cost test: [[13565.33662117]]\n",
      "   \n",
      " Epoch 11 cost train: [[8105.0515123]]\n",
      " Epoch 11 cost test: [[13389.31947423]]\n",
      "   \n",
      " Epoch 12 cost train: [[7988.44793097]]\n",
      " Epoch 12 cost test: [[13508.82589586]]\n",
      "   \n",
      " Epoch 13 cost train: [[8025.44368171]]\n",
      " Epoch 13 cost test: [[13788.54593282]]\n",
      "   \n",
      " Epoch 14 cost train: [[8007.72620338]]\n",
      " Epoch 14 cost test: [[13757.80566971]]\n",
      "   \n",
      " Epoch 15 cost train: [[8103.89614879]]\n",
      " Epoch 15 cost test: [[13893.53952578]]\n",
      "   \n",
      " Epoch 16 cost train: [[8098.25151316]]\n",
      " Epoch 16 cost test: [[13393.81545547]]\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "n_nodes = [10,30,50,100, 500]\n",
    "eta = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "lmd = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "epochs = [10,50,100]\n",
    "batch_s = [1,10,50]\n",
    "\n",
    "\n",
    "#for e in epochs:\n",
    "#    for b in batch_s:\n",
    "#        for et in eta:\n",
    "#            for n in n_nodes:\n",
    "model = NeuralNetRegressor(n_hidden = [30, 20],  \n",
    "                           epochs=100, \n",
    "                           eta=0.001, \n",
    "                           shuffle=True, \n",
    "                           batch_size=1,\n",
    "                           seed=None, \n",
    "                           alpha=0.0001, # dette er for relu ikke det samme som penaltien i scikit learn  \n",
    "                           activation='sigmoid')\n",
    "\n",
    "p = model.fit(X_train, y_train, X_test, y_test)\n",
    "l = model.predict(X_test)\n",
    "#print(\" \")\n",
    "#print( \" for epochs :\" + str(e) + \" for bactsize : \" + str(b) + \" learningrat e : \" + str(et) \n",
    "#+ \"noden in middle layer n: \" + str(n) + \" traininperformance ois \" + str(p.eval_['train_preform']) + \"validation performance is \"+ str(p.eval_['valid_preform']))\n",
    "#print(\" \")\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p.eval_['train_preform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p.eval_['valid_preform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = p.eval_['cost_train']\n",
    "te = p.eval_['cost_test']\n",
    "\n",
    "x = np.arange(100)\n",
    "temp = []\n",
    "temp2 = []\n",
    "for i in range(len(x)):\n",
    "    temp.append(tr[i][0][0])\n",
    "    temp2.append(te[i][0][0])\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(x,temp, label = \"cost train\")\n",
    "#plt.plot(x,temp2, label = \"cost test\")\n",
    "plt.legend()\n",
    "plt.savefig(\"results/figures/cost_nn_two_layers.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit MLP Regressor using one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#n_nodes = [10,30,50,100, 500]\n",
    "eta = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "lmd = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "#epochs = [10,50,100] Scikit stopper på rett antall epochs\n",
    "batch_s = [1,10,50]\n",
    "\n",
    "n, p = X_train.shape\n",
    "\n",
    "#for e in epochs:\n",
    "\n",
    "for b in batch_s:\n",
    "    for et in eta:\n",
    "        for l in lmd:\n",
    "            mlp = MLPRegressor(hidden_layer_sizes=(30,), \n",
    "                               activation = 'relu', # identity’, ‘logistic’, ‘tanh’, ‘relu’\n",
    "                               solver = \"adam\", \n",
    "                               alpha = l, # penalty\n",
    "                               batch_size = b, \n",
    "                               learning_rate_init = et)\n",
    "\n",
    "            mlp.fit(X_train, y_train)\n",
    "            y_pred = mlp.predict(X_test)\n",
    "            #logistic activation uses the sigmoid function \n",
    "            mse = NRMSE(y_pred, y_test)\n",
    "            ajusted_r2 = A_R2(y_pred, y_test, n, p)\n",
    "            print(\" eta : \" + str(et) + \" lmd \"+ str(l) +\"    batch size : \" +  str(b)   + \"   mse is \" + str(mse) + \" a r2  \" + str(ajusted_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding regularization may result in a better preformance despite of the network architecture ..? Doen't apper to be so, but check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
