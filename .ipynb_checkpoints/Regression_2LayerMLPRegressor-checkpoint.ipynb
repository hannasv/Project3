{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part d: regression on a multilayer perceptron (neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "np.random.seed(12)\n",
    "\n",
    "import warnings\n",
    "#Comment this to turn on warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from model_comparison import model_comparison\n",
    "from resample import resample\n",
    "import algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import netCDF4 as n\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import train_test_split\n",
    "from ann import NeuralNetMLP\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading test\n",
    "path = \"./files/\"\n",
    "filenames = [\"specific_humidity_Europa_sp.nc\", \"relative_humidity_Europa_sp.nc\", \"pressure_Europa_sp.nc\",  \n",
    "             \"temperature_Europa_sp.nc\", \"total_cloud_cover_Europa_sp.nc\"]\n",
    "\n",
    "\n",
    "cloud = n.Dataset(path + filenames[-1], \"r\")\n",
    "relative = n.Dataset(path + filenames[1], \"r\")\n",
    "specific = n.Dataset(path + filenames[0], \"r\")\n",
    "pressure = n.Dataset(path + filenames[2], \"r\")\n",
    "temperature = n.Dataset(path + filenames[3], \"r\")\n",
    "\n",
    "#print(cloud.variables)\n",
    "tcc = cloud.variables[\"tcc\"][:].data\n",
    "\n",
    "# Retriving ground values, these are available at six different pressure levels. \n",
    "rel = relative.variables[\"r\"][:][0].data\n",
    "#level = relative.variables[\"level\"][:][0].data\n",
    "spe = specific.variables[\"q\"][:][0].data\n",
    "\n",
    "surf_pre = pressure.variables[\"sp\"][:].data\n",
    "temp = temperature.variables[\"t2m\"][:].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_inv(x):\n",
    "    return np.exp(x)/(1+np.exp(x))\n",
    "\n",
    "def logit(x):\n",
    "    return np.log(x/(1-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one certain timestep \n",
    "t = 1\n",
    "\n",
    "y = tcc[t].flatten().reshape((4697, 1)) #logit(tcc[0].flatten()).reshape((4697, 1))\n",
    "X = np.array([rel[t].flatten(), spe[t].flatten(), surf_pre[t].flatten(), temp[t].flatten()]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, split_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3758, 4), (939, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3758, 1), (939, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two layer MLP (Neural network )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used to make table in report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NeuralNetMLP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9dbcd3dc1f44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             ann = NeuralNetMLP(n_hidden=30, \n\u001b[0m\u001b[1;32m     14\u001b[0m                                \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NeuralNetMLP' is not defined"
     ]
    }
   ],
   "source": [
    "# Experimental setup\n",
    "metric = []\n",
    "\n",
    "eta = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "#lmd = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "epochs = [1, 10, 50, 100]\n",
    "batchsize = [1, 10, 50]\n",
    "\n",
    "\n",
    "for epoch in epochs:\n",
    "    for e in eta:\n",
    "        for batch in batchsize:\n",
    "            ann = NeuralNetMLP(n_hidden=30, \n",
    "                               epochs=epoch, \n",
    "                               eta=e, \n",
    "                               shuffle=True,\n",
    "                               batch_size=batch, \n",
    "                               activation='sigmoid', \n",
    "                               tpe = \"regression\")\n",
    "\n",
    "            ann.fit(X_train, y_train, X_test, y_test)\n",
    "            ann.predict(X_test)\n",
    "            # returns a list of the mean mse score for different epochs or batches\n",
    "            metric.append(ann.eval_[\"valid_preform\"])\n",
    "            print(\"Sigmoid for nr of epochs \"+str(epoch) + \" and eta: \" + str(e) + \"  batchsize = \" + str(batch) +\"   performance is \" + str(np.nanmean(ann.eval_[\"valid_preform\"])))\n",
    "        print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental setup\n",
    "metric = []\n",
    "\n",
    "eta = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "#lmd = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "epochs = [1, 10, 50, 100]\n",
    "batchsize = [1, 10, 50]\n",
    "\n",
    "# Om vi skal bruke elu så må vi tweeke alpha i tilegg.\n",
    "\n",
    "\n",
    "for epoch in epochs:\n",
    "    for e in eta:\n",
    "        for batch in batchsize:\n",
    "            ann = NeuralNetMLP(n_hidden=30, \n",
    "                               epochs=epoch, \n",
    "                               eta=e, \n",
    "                               alpha = 0.0001,\n",
    "                               shuffle=True,\n",
    "                               batch_size=batch, \n",
    "                               activation='elu', \n",
    "                               tpe = \"regression\")\n",
    "\n",
    "            ann.fit(X_train, y_train, X_valid, y_valid)\n",
    "            ann.predict(X_valid)\n",
    "            # returns a list of the mean mse score for different epochs or batches\n",
    "            metric.append(ann.eval_[\"valid_preform\"])\n",
    "            print(\"ELU for nr of epochs \"+str(epoch) + \" and eta: \" + str(e) + \"  batchsize = \" + str(batch) +\"   performance is \" + str(np.nanmean(ann.eval_[\"valid_preform\"])))\n",
    "        print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance pr epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_m = []\n",
    "train_m = []\n",
    "\n",
    "eta = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "for e in eta:\n",
    "    ann = NeuralNetMLP(batch_size=10,\n",
    "                       epochs=50,\n",
    "                       n_hidden=30,\n",
    "                       eta = e,\n",
    "                       activation=\"sigmoid\",\n",
    "                       tpe = \"regression\")\n",
    "\n",
    "    ann.fit(X_train, y_train, X_valid, y_valid)\n",
    "    ann.predict(X_valid)\n",
    "    \n",
    "    test_m.append(ann.eval_[\"valid_preform\"])\n",
    "    train_m.append(ann.eval_[\"train_preform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "x = np.arange(len(test_m[0]))\n",
    "\n",
    "for i in range(2):\n",
    "    plt.plot(x, test_m[i], label = \"testdata, eta = %.4f\" %eta[i])\n",
    "    plt.plot(x, train_m[i], label = \"traindata, eta = %.4f\" %eta[i])\n",
    "    \n",
    "plt.title(\" Performance of MLPRegressor, sigmoid  \", fontsize = 20)\n",
    "xmin, xmax, ymin, ymax = plt.axis([0,50,0,50])\n",
    "plt.xlabel(\" Epoch \", fontsize=15)\n",
    "plt.ylabel(\"  MSE  \", fontsize=15)\n",
    "plt.legend()\n",
    "plt.savefig(\"./results/figures/MLPRegressor_sigmoid_MSE_50_epochs.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploding gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = NeuralNetMLP(batch_size=10,\n",
    "                   epochs=50,\n",
    "                   n_hidden=30,\n",
    "                   eta = 0.1,\n",
    "                   activation=\"sigmoid\",\n",
    "                   tpe = \"regression\")\n",
    "\n",
    "ann.fit(X_train, y_train, X_valid, y_valid)\n",
    "ann.predict(X_valid)\n",
    "\n",
    "ann.eval_[\"valid_preform\"], ann.eval_[\"train_preform\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparing to scikitlearn MLPregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from utils import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(30, ), \n",
    "                   activation = 'logistic', # this is the sigmoid activation function\n",
    "                   solver = \"sgd\", \n",
    "                   alpha = 0.0001, \n",
    "                   batch_size =10, \n",
    "                   learning_rate_init=0.0001)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_valid)\n",
    "#logistic activation uses the sigmoid function \n",
    "mean_squared_error(y_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(30, ), \n",
    "                   activation = 'relu', # similar to both elu and lrelu but it is zero for negative values.\n",
    "                   solver = \"sgd\", \n",
    "                   alpha = 0.0001, # out lmd\n",
    "                   batch_size =10, \n",
    "                   learning_rate_init=0.0001)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
