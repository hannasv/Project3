{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting cloud cover using neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "np.random.seed(12)\n",
    "\n",
    "import warnings\n",
    "#Comment this to turn on warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from model_comparison import model_comparison\n",
    "from resample import resample\n",
    "import algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import netCDF4 as n\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils import train_test_split\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from deepNN import NeuralNetRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from utils import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading test\n",
    "path = \"./files/\"\n",
    "filenames = [\"specific_humidity_Europa_sp.nc\", \"relative_humidity_Europa_sp.nc\", \"pressure_Europa_sp.nc\",  \n",
    "             \"temperature_Europa_sp.nc\", \"total_cloud_cover_Europa_sp.nc\"]\n",
    "\n",
    "\n",
    "cloud = n.Dataset(path + filenames[-1], \"r\")\n",
    "relative = n.Dataset(path + filenames[1], \"r\")\n",
    "specific = n.Dataset(path + filenames[0], \"r\")\n",
    "pressure = n.Dataset(path + filenames[2], \"r\")\n",
    "temperature = n.Dataset(path + filenames[3], \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cloud.variables)\n",
    "tcc = cloud.variables[\"tcc\"][:][:][:].data\n",
    "\n",
    "# Retriving ground values, these are available at six different pressure levels. \n",
    "rel = relative.variables[\"r\"][:][:][:][:].data\n",
    "#level = relative.variables[\"level\"][:][0].data\n",
    "spe = specific.variables[\"q\"][:][:][:][:].data\n",
    "\n",
    "surf_pre = pressure.variables[\"sp\"][:][:][:].data\n",
    "temp = temperature.variables[\"t2m\"][:][:][:].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_inv(x): # sigmoid?\n",
    "    return np.exp(x)/(1+np.exp(x))\n",
    "\n",
    "def logit(x):\n",
    "    return np.log((x + 1e-12)/(1+1e-12 - x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one certain timestep \n",
    "\n",
    "n_days = 0.25\n",
    "\n",
    "TCC = []\n",
    "REL = []\n",
    "SPE = []\n",
    "PRE = []\n",
    "TEMP = []\n",
    "\n",
    "\n",
    "for t in range(int(n_days*4)):\n",
    "    TCC.append(tcc[t].flatten())\n",
    "    REL.append(rel[t][0].flatten())\n",
    "    SPE.append(spe[t][0].flatten())\n",
    "    PRE.append(surf_pre[t].flatten())\n",
    "    TEMP.append(temp[t].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =(np.array(TCC).flatten())\n",
    "temp = y[y<1]\n",
    "y[y>1] = temp.max()\n",
    "X = np.array([np.array(REL).flatten(), np.array(SPE).flatten(), np.array(PRE).flatten(), np.array(TEMP).flatten()])\n",
    "y = logit(np.array(TCC).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.99866855977416e-13, 1.0000000000009999)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(TCC).min(), np.array(TCC).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-26.93794050959591, 36.04365338911916)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min(), y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 4697), (4697,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X), np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape((len(y),1))\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4697, 4), (4697, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X), np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, split_size = 0.2)\n",
    "import sklearn.model_selection as s\n",
    "X_train, X_test, y_train, y_test = s.train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3757, 4), (3757, 1), (940, 4), (940, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train), np.shape(y_train), np.shape(X_test), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36.04365338911916, -26.93794050959591)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.max(), y_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-27.63102111592955, 27.63093221929863)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit(0), logit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor e in epochs:\\n    for b in batch_s:\\n        for et in eta:\\n            for n in n_nodes:\\n                model = NeuralNetRegressor(n_hidden = [30, n, 20],  \\n                                           epochs=e, \\n                                           eta=et, \\n                                           shuffle=True, \\n                                           batch_size=b,\\n                                           seed=None, \\n                                           alpha=0.0001, \\n                                           activation=\\'sigmoid\\')\\n\\n                p = model.fit(X_train, y_train, X_test, y_test)\\n                l = model.predict(X_test)\\n                print(\" \")\\n                print( \" for epochs :\" + str(e) + \" for bactsize : \" + str(b) + \" learningrat e : \" + str(et) + \"noden in middle layer n: \" + str(n) + \" traininperformance ois \" + str(p.eval_[\\'train_preform\\']) + \"validation performance is \"+ str(p.eval_[\\'valid_preform\\']))\\n                print(\" \")\\n                \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_nodes = [10,30,50,100, 500]\n",
    "eta = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "lmd = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "epochs = [10,50,100]\n",
    "batch_s = [1,10,50]\n",
    "\n",
    "\"\"\"\n",
    "for e in epochs:\n",
    "    for b in batch_s:\n",
    "        for et in eta:\n",
    "            for n in n_nodes:\n",
    "                model = NeuralNetRegressor(n_hidden = [30, n, 20],  \n",
    "                                           epochs=e, \n",
    "                                           eta=et, \n",
    "                                           shuffle=True, \n",
    "                                           batch_size=b,\n",
    "                                           seed=None, \n",
    "                                           alpha=0.0001, \n",
    "                                           activation='sigmoid')\n",
    "\n",
    "                p = model.fit(X_train, y_train, X_test, y_test)\n",
    "                l = model.predict(X_test)\n",
    "                print(\" \")\n",
    "                print( \" for epochs :\" + str(e) + \" for bactsize : \" + str(b) + \" learningrat e : \" + str(et) + \"noden in middle layer n: \" + str(n) + \" traininperformance ois \" + str(p.eval_['train_preform']) + \"validation performance is \"+ str(p.eval_['valid_preform']))\n",
    "                print(\" \")\n",
    "                \n",
    "\"\"\"                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p.eval_['train_preform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.eval_['valid_preform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.02530017, -26.93794051, -26.93794051, ..., -26.93794051,\n",
       "        -0.72208271,   3.77878821])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit MLP Regressor using several layers of depth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eta : 0.0001 lmd :   0.0001    batch size : 1   mse is 221.28791670137886\n",
      " eta : 0.0001 lmd :   0.001    batch size : 1   mse is 221.2936133380667\n",
      " eta : 0.0001 lmd :   0.01    batch size : 1   mse is 221.3189646416359\n",
      " eta : 0.0001 lmd :   0.1    batch size : 1   mse is 221.35573206317684\n",
      " eta : 0.0001 lmd :   1.0    batch size : 1   mse is 221.30547151686272\n",
      " eta : 0.0001 lmd :   10    batch size : 1   mse is 221.34754495060636\n",
      " eta : 0.001 lmd :   0.0001    batch size : 1   mse is 221.54619772970133\n",
      " eta : 0.001 lmd :   0.001    batch size : 1   mse is 221.31741787209108\n",
      " eta : 0.001 lmd :   0.01    batch size : 1   mse is 221.33462334729575\n",
      " eta : 0.001 lmd :   0.1    batch size : 1   mse is 221.28790047169582\n",
      " eta : 0.001 lmd :   1.0    batch size : 1   mse is 221.29611414083394\n",
      " eta : 0.001 lmd :   10    batch size : 1   mse is 221.52063614689658\n",
      " eta : 0.01 lmd :   0.0001    batch size : 1   mse is 222.0242270396313\n",
      " eta : 0.01 lmd :   0.001    batch size : 1   mse is 221.3788389043341\n",
      " eta : 0.01 lmd :   0.01    batch size : 1   mse is 222.50728982657498\n",
      " eta : 0.01 lmd :   0.1    batch size : 1   mse is 221.28849228450235\n",
      " eta : 0.01 lmd :   1.0    batch size : 1   mse is 221.2925676819386\n",
      " eta : 0.01 lmd :   10    batch size : 1   mse is 221.47319654336613\n",
      " eta : 0.1 lmd :   0.0001    batch size : 1   mse is 238.56833366151224\n",
      " eta : 0.1 lmd :   0.001    batch size : 1   mse is 226.8896307565273\n",
      " eta : 0.1 lmd :   0.01    batch size : 1   mse is 223.26341043793568\n",
      " eta : 0.1 lmd :   0.1    batch size : 1   mse is 228.63130491698604\n",
      " eta : 0.1 lmd :   1.0    batch size : 1   mse is 222.89855340125754\n",
      " eta : 0.1 lmd :   10    batch size : 1   mse is 221.49141983018657\n",
      " eta : 1.0 lmd :   0.0001    batch size : 1   mse is 401.3621933795109\n",
      " eta : 1.0 lmd :   0.001    batch size : 1   mse is 236.48547718964676\n",
      " eta : 1.0 lmd :   0.01    batch size : 1   mse is 248.77300314927163\n",
      " eta : 1.0 lmd :   0.1    batch size : 1   mse is 677.0263398496571\n",
      " eta : 1.0 lmd :   1.0    batch size : 1   mse is 221.9287209817275\n",
      " eta : 1.0 lmd :   10    batch size : 1   mse is 230.20309214325246\n",
      " eta : 0.0001 lmd :   0.0001    batch size : 10   mse is 221.34523350554272\n",
      " eta : 0.0001 lmd :   0.001    batch size : 10   mse is 221.35327489095047\n",
      " eta : 0.0001 lmd :   0.01    batch size : 10   mse is 221.3444758542219\n",
      " eta : 0.0001 lmd :   0.1    batch size : 10   mse is 221.33671494080406\n",
      " eta : 0.0001 lmd :   1.0    batch size : 10   mse is 221.2889038693573\n",
      " eta : 0.0001 lmd :   10    batch size : 10   mse is 221.28770616993967\n",
      " eta : 0.001 lmd :   0.0001    batch size : 10   mse is 221.49184581787966\n",
      " eta : 0.001 lmd :   0.001    batch size : 10   mse is 221.33998226956135\n",
      " eta : 0.001 lmd :   0.01    batch size : 10   mse is 221.3664712369473\n",
      " eta : 0.001 lmd :   0.1    batch size : 10   mse is 221.2878661444657\n",
      " eta : 0.001 lmd :   1.0    batch size : 10   mse is 221.28775879996272\n",
      " eta : 0.001 lmd :   10    batch size : 10   mse is 221.37571342002104\n",
      " eta : 0.01 lmd :   0.0001    batch size : 10   mse is 221.4181620650329\n",
      " eta : 0.01 lmd :   0.001    batch size : 10   mse is 221.43780141639974\n",
      " eta : 0.01 lmd :   0.01    batch size : 10   mse is 223.13187637575044\n",
      " eta : 0.01 lmd :   0.1    batch size : 10   mse is 221.50672830601945\n",
      " eta : 0.01 lmd :   1.0    batch size : 10   mse is 221.29681857199836\n",
      " eta : 0.01 lmd :   10    batch size : 10   mse is 221.40876238634394\n",
      " eta : 0.1 lmd :   0.0001    batch size : 10   mse is 226.63536065523232\n",
      " eta : 0.1 lmd :   0.001    batch size : 10   mse is 224.11471621781368\n",
      " eta : 0.1 lmd :   0.01    batch size : 10   mse is 224.88666951591446\n",
      " eta : 0.1 lmd :   0.1    batch size : 10   mse is 221.56227832456983\n",
      " eta : 0.1 lmd :   1.0    batch size : 10   mse is 221.81943982912904\n",
      " eta : 0.1 lmd :   10    batch size : 10   mse is 221.76942691306576\n",
      " eta : 1.0 lmd :   0.0001    batch size : 10   mse is 223.24491094640834\n",
      " eta : 1.0 lmd :   0.001    batch size : 10   mse is 245.62221048726124\n",
      " eta : 1.0 lmd :   0.01    batch size : 10   mse is 223.63868791288743\n",
      " eta : 1.0 lmd :   0.1    batch size : 10   mse is 222.21696548117797\n",
      " eta : 1.0 lmd :   1.0    batch size : 10   mse is 221.29060946225735\n",
      " eta : 1.0 lmd :   10    batch size : 10   mse is 222.04046015881235\n",
      " eta : 0.0001 lmd :   0.0001    batch size : 50   mse is 221.32596113520674\n",
      " eta : 0.0001 lmd :   0.001    batch size : 50   mse is 221.31996250637891\n",
      " eta : 0.0001 lmd :   0.01    batch size : 50   mse is 221.3134862187776\n",
      " eta : 0.0001 lmd :   0.1    batch size : 50   mse is 221.30428174043016\n",
      " eta : 0.0001 lmd :   1.0    batch size : 50   mse is 221.28939597546233\n",
      " eta : 0.0001 lmd :   10    batch size : 50   mse is 221.28760785353617\n",
      " eta : 0.001 lmd :   0.0001    batch size : 50   mse is 221.33962514049242\n",
      " eta : 0.001 lmd :   0.001    batch size : 50   mse is 221.34099017994657\n",
      " eta : 0.001 lmd :   0.01    batch size : 50   mse is 221.37914270229334\n",
      " eta : 0.001 lmd :   0.1    batch size : 50   mse is 221.57621563130724\n",
      " eta : 0.001 lmd :   1.0    batch size : 50   mse is 221.32191598179506\n",
      " eta : 0.001 lmd :   10    batch size : 50   mse is 221.359977258931\n",
      " eta : 0.01 lmd :   0.0001    batch size : 50   mse is 221.2990193567528\n",
      " eta : 0.01 lmd :   0.001    batch size : 50   mse is 221.45803839779109\n",
      " eta : 0.01 lmd :   0.01    batch size : 50   mse is 221.5912187399044\n",
      " eta : 0.01 lmd :   0.1    batch size : 50   mse is 221.588658057096\n",
      " eta : 0.01 lmd :   1.0    batch size : 50   mse is 222.053737956829\n",
      " eta : 0.01 lmd :   10    batch size : 50   mse is 222.45297600326117\n",
      " eta : 0.1 lmd :   0.0001    batch size : 50   mse is 221.31682019601382\n",
      " eta : 0.1 lmd :   0.001    batch size : 50   mse is 222.47695755106838\n",
      " eta : 0.1 lmd :   0.01    batch size : 50   mse is 225.8435953517956\n",
      " eta : 0.1 lmd :   0.1    batch size : 50   mse is 222.0426515350395\n",
      " eta : 0.1 lmd :   1.0    batch size : 50   mse is 223.52126000375702\n",
      " eta : 0.1 lmd :   10    batch size : 50   mse is 222.35355710585745\n",
      " eta : 1.0 lmd :   0.0001    batch size : 50   mse is 222.82785316919774\n",
      " eta : 1.0 lmd :   0.001    batch size : 50   mse is 224.47034839100405\n",
      " eta : 1.0 lmd :   0.01    batch size : 50   mse is 222.20710457734486\n",
      " eta : 1.0 lmd :   0.1    batch size : 50   mse is 356.5379293586103\n",
      " eta : 1.0 lmd :   1.0    batch size : 50   mse is 238.63661029438333\n",
      " eta : 1.0 lmd :   10    batch size : 50   mse is 223.33058647599498\n"
     ]
    }
   ],
   "source": [
    "n_nodes = [10,30,50,100, 500]\n",
    "eta = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "lmd = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "epochs = [10,50,100]\n",
    "batch_s = [1,10,50]\n",
    "\n",
    "\n",
    "\n",
    "#for e in epochs:\n",
    "for b in batch_s:\n",
    "    for et in eta:\n",
    "        for l in lmd:\n",
    "            mlp = MLPRegressor(hidden_layer_sizes=(100, 50), \n",
    "                               activation = 'logistic', # this is the sigmoid activation function\n",
    "                               solver = \"adam\", \n",
    "                               alpha = l, # penalty\n",
    "                               batch_size =b, \n",
    "                               learning_rate_init=et)\n",
    "\n",
    "            mlp.fit(X_train, y_train)\n",
    "            y_pred = mlp.predict(X_test)\n",
    "            #logistic activation uses the sigmoid function \n",
    "            mse = mean_squared_error(y_pred, y_test)\n",
    "            print(\" eta : \" + str(et) +   \" lmd :   \"   + str(l) + \"    batch size : \" +  str(b)   + \"   mse is \" + str(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding regularization may result in a beytte preformance despite of the network architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
