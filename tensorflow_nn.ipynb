{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks using tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as n\n",
    "%matplotlib inline\n",
    "from utils import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./files/\"\n",
    "filenames = [\"specific_humidity_Europa_sp.nc\", \"relative_humidity_Europa_sp.nc\", \"pressure_Europa_sp.nc\",  \n",
    "             \"temperature_Europa_sp.nc\", \"total_cloud_cover_Europa_sp.nc\"]\n",
    "\n",
    "\n",
    "cloud = n.Dataset(path + filenames[-1], \"r\")\n",
    "relative = n.Dataset(path + filenames[1], \"r\")\n",
    "specific = n.Dataset(path + filenames[0], \"r\")\n",
    "pressure = n.Dataset(path + filenames[2], \"r\")\n",
    "temperature = n.Dataset(path + filenames[3], \"r\")\n",
    "\n",
    "my_files = {'cloud':cloud, 'relative':relative, 'specific':specific, 'pressure':pressure, 'temperature':temperature}\n",
    "\n",
    "\n",
    "tcc = cloud.variables[\"tcc\"]\n",
    "rh = relative.variables[\"r\"]\n",
    "q = specific.variables[\"q\"]\n",
    "sp = pressure.variables[\"sp\"]\n",
    "t2m = temperature.variables[\"t2m\"]\n",
    "\n",
    "my_vars = {'tcc':tcc, 'rh':rh, 'q':q, 'sp':sp, 't2m':t2m}\n",
    "\n",
    "\n",
    "X = np.empty((tcc.shape[1]*tcc.shape[2], 4))\n",
    "y = np.empty((tcc.shape[1]*tcc.shape[2], 1))\n",
    "\n",
    "i=0\n",
    "for key, value in my_vars.items():\n",
    "    if key == 'tcc':\n",
    "        y = np.array(value[0, : , :]).flatten()\n",
    "    elif key == 'rh' or key == 'q':\n",
    "        X[:, i] = np.array(value[0, 0, : , :]).flatten()\n",
    "        i = i+1\n",
    "    else:\n",
    "        X[:, i] = np.array(value[0, : , :]).flatten()\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn = (X - X.mean())/X.std()\n",
    "yn = (y - y.mean())/y.std()\n",
    "\n",
    "Xn_train, Xn_test, yn_train, yn_test = train_test_split(Xn, yn, split_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn_train = tf.cast(Xn_train, tf.float32)  # convert to float 32 so that we can use tf.matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed forward neural net with 2 layers. Activation function: Sigmoid for all layers.\n",
    "\n",
    "TODO: write as function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "npred = Xn_train.shape[1]  # number of predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using normal distribution (maybe change this)\n",
    "\n",
    "W_1 = tf.Variable(tf.random_uniform([npred,10]))\n",
    "b_1 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define layer 1 and activation f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = tf.add(tf.matmul(Xn_train,W_1), b_1)\n",
    "# layer_1 = tf.nn.relu(layer_1)\n",
    "layer_1 = tf.nn.sigmoid(layer_1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = tf.nn.relu(layer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiply by layer 1 and add bias. Then activation function\n",
    "#### Obtain layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_2 = tf.Variable(tf.random_uniform([10,10]))\n",
    "b_2 = tf.Variable(tf.zeros([10]))\n",
    "layer_2 = tf.add(tf.matmul(layer_1,W_2), b_2)\n",
    "layer_2 = tf.nn.sigmoid(layer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiply by layer 2 and add bias. Then activation function\n",
    "#### Obtain output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = tf.Variable(tf.random_uniform([10,1]))\n",
    "b_O = tf.Variable(tf.zeros([1]))\n",
    "output = tf.add(tf.matmul(layer_2,W_O), b_O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xs = tf.placeholder(\"float\")\n",
    "#ys = tf.placeholder(\"float\")\n",
    "#output = neural_net_model(xs,3)\n",
    "cost = tf.reduce_mean(tf.square(output-yn_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.001\n",
    "train = tf.train.GradientDescentOptimizer(eta).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tflow]",
   "language": "python",
   "name": "conda-env-tflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
